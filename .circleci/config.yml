defaults: &defaults
  docker:
    - image: continuumio/miniconda3
  environment:
    DATABASE_DIR: databases


version: 2

jobs:
  build:
    <<: *defaults
    resource_class: small
    environment:
      N_THREADS: 1
      MEM: 2
      WORKING_DIR: .test/Dryrun
    steps:
      - checkout
      - run: pwd
      - run:
          name: Setup conda
          command: |
           conda config --add channels bioconda
           conda config --add channels conda-forge
           conda config --set always_yes true
           conda install -y mamba
      - restore_cache:
          key: atlasenv-d-{{ checksum "atlasenv.yml" }}
      - run:
          name: install dependencies
          command:  |
              if [ -d "./atlasenv" ]; then
                echo "atlasenv exist already";
                source activate ./atlasenv
                conda list
              else
                mamba env create -p ./atlasenv --file atlasenv.yml
              fi
      - save_cache:
          key: atlasenv-d-{{ checksum "atlasenv.yml" }}
          paths:
            - "./atlasenv"
      - run:
          name: Install atlas
          command: |
              source activate ./atlasenv
              python setup.py install
              conda list
              atlas --help
              atlas --version
      - run:
          name: short test
          command: |
              source activate ./atlasenv
              atlas --help
              atlas --version
      - run:
          name: Dryrun
          command: |
              source activate ./atlasenv
              .test/dryrun.sh

      - persist_to_workspace:
          root: /root/project/
          paths:
            - ./atlasenv
            - .

  getenvs:
    <<: *defaults
    resource_class: small
    steps:
      - attach_workspace:
          at: /root/project/
      - run: tar -cf conda_envs.tar atlas/envs
      - restore_cache:
          keys:
            - requirements-{{ checksum "conda_envs.tar"  }}
            - requirements-
            - conda-environements-

      - run:
          name: Init
          command: |
              source activate ./atlasenv
              atlas init --db-dir $DATABASE_DIR --threads 1 -w .test/Getenvs .test/reads/empty
      - run:
          name: install environements
          command: |
              source activate ./atlasenv
              atlas run all -w .test/Getenvs --create-envs-only --omit-from build_qc_report build_assembly_report build_bin_report
      - run:
          name: download checkm data
          command: |
              source activate ./atlasenv
              atlas run None -w .test/Getenvs logs/checkm_init.txt
      - save_cache:
          key: requirements-{{ checksum "conda_envs.tar"  }}
          paths:
            - databases

      - persist_to_workspace:
          root: /root/project/
          paths:
            - databases


  get_example_data:
    <<: *defaults
    environment:
    resource_class: small
    steps:
      - run: git clone https://github.com/metagenome-atlas/example_data.git
      - persist_to_workspace:
          root: /root/project
          paths:
            - example_data

  assembly_and_genecatalog:
    <<: *defaults
    environment:
      N_THREADS: 2
      MEM: 4
    resource_class: medium
    steps:
      - attach_workspace:
          at: /root/project/
      - run: tar -cf conda_envs.tar atlas/envs
      - restore_cache:
          keys:
            - requirements-{{ checksum "conda_envs.tar"  }}
            - requirements-
            - conda-environements-
      - run:
          name: test assembly
          command: |
              source activate ./atlasenv
              .test/test_assembly.sh --resources mem=$MEM java_mem=$MEM --config  threads=$N_THREADS mem=$MEM --jobs=$N_THREADS --restart-times=2 --omit-from build_qc_report build_assembly_report
      - run:
          command: |
            mkdir -p /tmp/logs/snakemake
            cp -r .test/Test_assembly/Streptococcus/logs /tmp/logs/Streptococcus
            cp -r .test/Test_assembly/Mycoplasma/logs /tmp/logs/Mycoplasma
            cp -r .test/Test_assembly/logs /tmp/logs/global
            cp -r .test/Test_assembly/.snakemake/log/* /tmp/logs/snakemake
          when: on_fail
      - store_artifacts:
          path: /tmp/logs
          destination: assembly_logs
      - store_test_results:
          path: .test/Test_assembly/reports
      - store_artifacts:
          path: .test/Test_assembly/reports
          destination: assembly_results


      - run:
          name: run genecatalog
          command: |
              source activate ./atlasenv
              WD='.test/Test_assembly'
              atlas run None "Genecatalog/clustering/orf2gene.tsv.gz" -w $WD --resources mem=$MEM java_mem=$MEM --jobs=$N_THREADS --restart-times=2
      - store_test_results:
          path: .test/Test_assembly
      - store_artifacts:
          path: .test/Test_assembly
          destination: assembly_results

  binning:
    <<: *defaults
    environment:
      N_THREADS: 2
      MEM: 4
      databaseDir: "databases"
      WD: 'example_data/binning'
      reads_dir: "example_data/reads/test"
      config: "--config mem=4 java_mem=4 --resources mem=4 java_mem=4 --jobs=2"

    resource_class: medium
    steps:
      - attach_workspace:
          at: /root/project/
      - run: tar -cf conda_envs.tar atlas/envs
      - restore_cache:
          keys:
            - requirements-{{ checksum "conda_envs.tar"  }}
            - requirements-
            - conda-environements-

      - run:
          name: init
          command: |
            source activate ./atlasenv
            atlas init --db-dir $databaseDir --threads $N_THREADS  -w $WD --skip-qc --interleaved-fastq $reads_dir

            touch -m $WD/finished_assembly
            touch -m $WD/sample*/*/*.bam # update timestamp of sam files
      - restore_cache:
          keys:
            - binning-{{ .Branch }}
            - binning-
      - run:
          name: assembly
          command: |
            source activate ./atlasenv
            atlas run assembly $config -w $WD
      - save_cache:
          key: binning-{{ .Branch }}-assembly
          paths:
            - example_data/binning
      - run:
          name: until checkm
          command: |
            source activate ./atlasenv
            atlas run binning --omit-from run_checkm_lineage_wf $config -w $WD
      - run:
          name: Copy checkm files
          command: |
            for s in sample1 sample2 ;
            do
              dest_dir=$WD/$s/binning/DASTool/checkm/
              rm -rf dest_dir
              mkdir -p $dest_dir
              cp -r $WD/checkm_results/$s/* $dest_dir
            done
      - save_cache:
          key: binning-{{ .Branch }}-binning
          paths:
            - example_data/binning

      - run:
          name: finish binning
          command: |
            source activate ./atlasenv
            atlas run binning $config -w $WD $@
      - save_cache:
          key: binning-{{ .Branch }}-binreport
          paths:
            - example_data/binning
      - run:
          name: test genomes
          command: |
            source activate ./atlasenv
            rm -r $WD/genomes #start fresh as bin names are not teterministic
            atlas run None genomes/clustering/allbins2genome.tsv $config -w $WD
      - save_cache:
          key: binning-{{ .Branch }}-genomes
          paths:
            - example_data/binning
      - run:
          name: test genecatalog
          command: |
            source activate ./atlasenv
            atlas run None "Genecatalog/clustering/orf2gene.tsv.gz" $config -w $WD

      - save_cache:
          key: binning-{{ .Branch }}-Genecatalog
          paths:
            - example_data/binning
      - run:
          name: test all
          command: |
            source activate ./atlasenv
            atlas run None gene2genome $config -w $WD

      - store_test_results:
          path: example_data/binning
      - store_artifacts:
          path: example_data/binning
          destination: binning_results

  #
  #
  # build-docker:
  #   environment:
  #     IMAGE_NAME: metagenomeatlas/atlas
  #   docker:
  #     - image: circleci/buildpack-deps:stretch
  #   steps:
  #     - checkout
  #     - setup_remote_docker
  #     - run:
  #         name: Build Docker image
  #         command: docker build -t $IMAGE_NAME:latest .
  # publish-latest:
  #   environment:
  #     IMAGE_NAME: metagenomeatlas/atlas
  #   docker:
  #     - image: circleci/buildpack-deps:stretch
  #   steps:
  #     - setup_remote_docker
  #     - run:
  #         name: Publish Docker Image to Docker Hub
  #         command: |
  #           echo "$DOCKERHUB_PASS" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
  #           docker push $IMAGE_NAME:latest


workflows:
  version: 2
  build_and_test:
    jobs:
      - build
      - get_example_data
      - getenvs:
          requires:
            - build
      - assembly_and_genecatalog:
          requires:
            - build
            - get_example_data
      - binning:
          requires:
            - build
            - get_example_data
      # - build-docker:
      #     requires:
      #       - build
      #       - getenvs
      #       - assembly_and_genecatalog
      #     filters:
      #       branches:
      #         only: master
      # - publish-latest:
      #     requires:
      #       - build-docker
      #     filters:
      #       branches:
      #         only: master
